# MNIST Backend - API de Serving

Ce projet contient une API FastAPI conÃ§ue pour servir un modÃ¨le de reconnaissance de chiffres manuscrits (MNIST).

## ğŸ¯ RÃ´le dans l'architecture MLOps

Ce service constitue la brique de **Serving/Inference** de notre architecture. Il **NE GÃˆRE PAS** l'entraÃ®nement du modÃ¨le. Sa responsabilitÃ© unique est de :

1. **Charger** un artefact de modÃ¨le prÃ©-entraÃ®nÃ© (`convnet.pt`)
2. **Exposer** une API REST pour la prÃ©diction en temps rÃ©el
3. **PrÃ©processer** les images uploadÃ©es
4. **Retourner** les prÃ©dictions avec confiance

> âš ï¸ **Important** : L'entraÃ®nement du modÃ¨le est gÃ©rÃ© par le projet `kedro` avec des pipelines MLOps structurÃ©s.

## ğŸ—ï¸ Architecture

```
ğŸ“¦ mnist-backend/           # ğŸ¯ SERVING UNIQUEMENT
â”œâ”€â”€ src/api/               # API FastAPI
â”œâ”€â”€ src/models/            # DÃ©finitions de modÃ¨les (pas d'entraÃ®nement)
â”œâ”€â”€ models/                # Artefacts de modÃ¨les prÃ©-entraÃ®nÃ©s
â””â”€â”€ tests/                 # Tests de l'API

ğŸ“¦ kedro/                  # ğŸ‹ï¸ ENTRAÃNEMENT UNIQUEMENT  
â”œâ”€â”€ pipelines/             # Pipelines Kedro (data + training)
â”œâ”€â”€ conf/                  # Configuration MLOps
â””â”€â”€ data/                  # DonnÃ©es et artifacts MLflow
```

## ğŸ”„ Workflow de Production

1. **EntraÃ®nement** : `kedro run` (dans le projet kedro)
2. **Artefacts** : ModÃ¨le sauvegardÃ© dans `kedro/data/`
3. **Copie** : ModÃ¨le copiÃ© vers `mnist-backend/models/`
4. **Serving** : API chargÃ©e et prÃªte pour les prÃ©dictions

## ğŸš€ DÃ©marrage rapide

### PrÃ©requis
Assurez-vous qu'un modÃ¨le entraÃ®nÃ© existe dans `models/convnet.pt`. 
Si ce n'est pas le cas, entraÃ®nez d'abord avec Kedro :

```bash
# Dans le projet kedro/
kedro run
```

### Lancement de l'API

```bash
# Installation des dÃ©pendances
pip install -r requirements.txt

# Lancement de l'API
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000
```

## ğŸ“š API Endpoints

- `POST /api/v1/predict` - Classification d'image (upload fichier)
- `GET /health` - Statut de l'API  
- `GET /api/info` - Informations sur l'API et le modÃ¨le
- `GET /docs` - Documentation Swagger interactive
- `GET /redoc` - Documentation ReDoc

## ğŸ³ Docker

```bash
# Build
docker build -t mnist-backend .

# Run
docker run -p 8000:8000 mnist-backend

# Avec volume pour modÃ¨les
docker run -p 8000:8000 -v $(pwd)/models:/app/models mnist-backend
```

## ğŸ“ Structure du Projet

```
src/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py          # ğŸš€ API FastAPI
â””â”€â”€ models/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ convnet.py       # ğŸ§  DÃ©finition du modÃ¨le ConvNet
models/
â””â”€â”€ convnet.pt          # ğŸ’¾ ModÃ¨le prÃ©-entraÃ®nÃ© (depuis Kedro)
tests/
â”œâ”€â”€ unit/                # ğŸ§ª Tests unitaires
â”œâ”€â”€ integration/         # ğŸ”— Tests d'intÃ©gration  
â””â”€â”€ model_validation/    # âœ… Validation de modÃ¨le
```

## ğŸ§ª Tests

```bash
# Tests unitaires
pytest tests/unit/

# Tests d'intÃ©gration 
pytest tests/integration/

# Validation de modÃ¨le
pytest tests/model_validation/

# Tous les tests
pytest
```

## ğŸ”§ CI/CD Pipeline

Le workflow GitHub Actions automatise :

1. **Tests** : QualitÃ© de code (Black, Pylint, Flake8)
2. **Build** : Image Docker avec modÃ¨le
3. **Push** : Publication sur GitHub Container Registry
4. **Deploy** : PrÃªt pour dÃ©ploiement via `mnist-deployment`

## ğŸ¤ IntÃ©gration avec Kedro

Pour utiliser un nouveau modÃ¨le entraÃ®nÃ© :

```bash
# 1. EntraÃ®ner avec Kedro
cd ../kedro && kedro run

# 2. Copier le modÃ¨le
cp kedro/data/06_models/convnet.pt mnist-backend/models/

# 3. RedÃ©marrer l'API
# L'API chargera automatiquement le nouveau modÃ¨le
``` 