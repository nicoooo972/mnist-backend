from fastapi import FastAPI, File, UploadFile
import numpy as np
import torch
from PIL import Image
import io
import sys
import os
import multiprocessing

# D√©sactiver le multiprocessing
multiprocessing.set_start_method('spawn', force=True)

# Import du mod√®le
from ..models.convnet import ConvNet

app = FastAPI()

# Initialisation du mod√®le
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Charger le mod√®le avec ses param√®tres
model_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "models", "convnet.pt")
if os.path.exists(model_path):
    checkpoint = torch.load(model_path, map_location=device)
    
    # V√©rifier le format du mod√®le sauvegard√©
    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
        # Nouveau format avec m√©tadonn√©es
        n_kernels = checkpoint.get('n_kernels', 6)
        input_size = checkpoint.get('input_size', 1)
        output_size = checkpoint.get('output_size', 10)
        permutation = checkpoint.get('permutation', torch.randperm(784))
        
        model = ConvNet(input_size, n_kernels, output_size)
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        # Ancien format (juste les weights)
        print("Chargement d'un ancien mod√®le sans permutation sauvegard√©e")
        n_kernels = 6
        input_size = 1
        output_size = 10
        permutation = torch.randperm(784)  # Permutation al√©atoire
        
        model = ConvNet(input_size, n_kernels, output_size)
        model.load_state_dict(checkpoint)
else:
    raise FileNotFoundError(
        f"‚ùå Aucun mod√®le entra√Æn√© trouv√© √† {model_path}!\n"
        f"üöÄ Lancez d'abord: python train_model.py\n"
        f"üìÅ Le mod√®le sera sauvegard√© dans models/convnet.pt"
    )

model.to(device)
model.eval()

def preprocess_image(image_bytes: bytes) -> torch.Tensor:
    # Convertir l'image en PIL Image
    image = Image.open(io.BytesIO(image_bytes))
    # Convertir en niveaux de gris si n√©cessaire
    if image.mode != 'L':
        image = image.convert('L')
    # Redimensionner √† 28x28
    image = image.resize((28, 28))
    
    # Convertir en numpy array et normaliser avec les param√®tres MNIST
    image_array = np.array(image, dtype=np.float32) / 255.0
    # Inverser si n√©cessaire (MNIST a un fond noir)
    if image_array.mean() > 0.5:  # Si l'image est plus claire (fond blanc)
        image_array = 1.0 - image_array
    
    # Normalisation MNIST
    image_array = (image_array - 0.1307) / 0.3081
    
    # Convertir en tensor et appliquer la permutation
    image_tensor = torch.from_numpy(image_array.flatten())
    image_permuted = image_tensor[permutation]
    image_reshaped = image_permuted.view(1, 28, 28)
    
    return image_reshaped

def predict(image_tensor: torch.Tensor, model: torch.nn.Module) -> dict:
    # Ajouter la dimension batch
    image_tensor = image_tensor.unsqueeze(0).to(device)
    
    # Faire la pr√©diction
    with torch.no_grad():
        output = model(image_tensor)
        probabilities = torch.nn.functional.softmax(output, dim=1)
        predicted_class = torch.argmax(output, dim=1).item()
        confidence = probabilities[0][predicted_class].item()
    
    return {
        "predicted_class": int(predicted_class),
        "confidence": float(confidence),
        "probabilities": probabilities[0].cpu().numpy().tolist()
    }

@app.get("/")
async def root():
    return {"message": "API de classification MNIST", 
            "endpoints": {
                "predict": "/api/v1/predict",
                "docs": "/docs",
                "redoc": "/redoc"
            }}

@app.post("/api/v1/predict")
async def predict_endpoint(file: UploadFile = File(...)):
    # Lire l'image
    image_bytes = await file.read()
    
    # Pr√©traiter l'image (retourne maintenant un tensor avec permutation)
    image_tensor = preprocess_image(image_bytes)
    
    # Faire la pr√©diction
    result = predict(image_tensor, model)
    
    return result

@app.get("/health")
async def health():
    return {"status": "healthy", "service": "mnist-backend"}

@app.get("/api/info")  
async def info():
    return {"version": "1.0.0", "model": "ConvNet"}
